{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"17BXqmZlFyBMXEKcIS1tE3QY20MawaZFP","timestamp":1668223562947},{"file_id":"1Zx3fXMXeDhLkqGWnBB7u9MeMJHCGUwFy","timestamp":1657733385836},{"file_id":"1qaGAHkBJeadpiP2yHNdxsHgvzd02fsXO","timestamp":1646536096657},{"file_id":"1FEL--qACfEN3lHbqvWBtIFqkakjfAaY-","timestamp":1615448778766}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0KKC3O3QiIi4"},"source":["#ENGG*6600: Special Topics in Information Retrieval - Fall 2022\n","##Assignment 4: Relevance Models (Total : 100 points)\n","\n","**Description**\n","\n","This is a coding assignment where you will implement the RM1 model for Query Expansion. Basic proficiency in Python is recommended.  \n","\n","**Instructions**\n","\n","* To start working on the assignment, you would first need to save the notebook to your local Google Drive. For this purpose, you can click on *Copy to Drive* button. You can alternatively click the *Share* button located at the top right corner and click on *Copy Link* under *Get Link* to get a link and copy this notebook to your Google Drive.  \n","\n","*   For questions with descriptive answers, please replace the text in the cell which states \"Enter your answer here!\" with your answer. If you are using mathematical notation in your answers, please define the variables.\n","*   You should implement all the functions yourself and should not use a library or tool for the computation.\n","*   For coding questions, you can add code where it says \"enter code here\" and execute the cell to print the output.\n","* To create the final pdf submission file, execute *Runtime->RunAll* from the menu to re-execute all the cells and then generate a PDF using *File->Print->Save as PDF*. Make sure that the generated PDF contains all the codes and printed outputs before submission.\n","To create the final python submission file, click on File->Download .py.\n","\n","\n","**Submission Details**\n","\n","* Due data: Nov. 11, 2022 at 11:59 PM (EST).\n","* The final PDF and python file must be uploaded on GourseLink.\n","* After copying this notebook to your Google Drive, please paste a link to it below. Use the same process given above to generate a link. ***You will not recieve any credit if you don't paste the link!*** Make sure we can access the file.\n","***LINK: *https://colab.research.google.com/drive/1Imx2uUD3il2VSk8JJhGQgwPYPc7szSVr?usp=sharing***\n","\n","**Academic Honesty**\n","\n","Please follow the guidelines under the *Collaboration and Help* section in the first lecture."]},{"cell_type":"markdown","metadata":{"id":"JuVqvXU6ijXi"},"source":["# Download input files and code"]},{"cell_type":"markdown","metadata":{"id":"SMU5d1a-jCG-"},"source":["Please execute the cell below to download the input files."]},{"cell_type":"code","metadata":{"id":"YM1igiBMcIB8"},"source":["\n","import os\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","\n","import os\n","import zipfile\n","\n","download = drive.CreateFile({'id': '1CLVPQ0HADjmE0cPthdZ628aIYc8yvMdq'})\n","download.GetContentFile('HW04.zip')\n","\n","with zipfile.ZipFile('HW04.zip', 'r') as zip_file:\n","    zip_file.extractall('./')\n","os.remove('HW04.zip')\n","# We will use hw1 as our working directory\n","os.chdir('HW04')\n","\n","#Setting the input files\n","queries_file = \"queries_tok_clean_kstem\"\n","col = \"antique-collection.tok.clean_kstem\"\n","query_pass = \"query_pass\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T9GqDu_ilscP"},"source":["# 1 : Initial Data Setup (20 points)\n","\n","We use files from the ANTIQUE  [https://arxiv.org/pdf/1905.08957.pdf] dataset for this assignment. As described in the previous assignments, this is a passage retrieval dataset.\n","\n","The description of the input files provided for this assignment is given below.\n","\n","**Query File**\n","\n","We randomly sampled a set of 5 queries from the test set of the ANTIQUE dataset. Each row of the input file contains the following information:\n","\n","*query_id query_text*\n","\n","The id and text information is tab separated. query_id is a unique identifier for a query and query text has been pre-processed to remove punctutation, tokenised and stemmed using the Krovetz stemmer.  \n","\n","**Collection file**\n","\n","Each row of the file consists of the following information:\n","\n","*passage_id  passage_text*\n","\n","The id and text information is tab separated. The passage text has been pre-processed to remove punctutation, tokenised and stemmed using the Krovetz stemmer (same as queries). The terms in the passage text can be accessed by splitting the text based on space.\n","\n","**Query Feedback Passages**\n","\n","This file consists of queries and 10 feedback passages corresponding to each query.  Each row of the file consists of the following information:\n","\n","*query_id  passage_id1 passage_id2 ......passage_id10*\n","\n","The entries are space separated. The first column is the query_id followed by the passage_ids.\n","\n","In this section, you have to implement the following:\n","\n","* Load the queries from the query file into a datastructure\n","* Load the query feedback passages into a datastructure.\n","\n","You can use any additional datastructures than the suggested ones for your implementation.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"XDsPg_A8oZlF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668223916577,"user_tz":300,"elapsed":28,"user":{"displayName":"Harsh Shah","userId":"05727327381693060940"}},"outputId":"de667152-d24b-46f0-eeff-d9fa94704cc3"},"source":["\n","'''\n","This function is used to load query file information into datastructure(s).\n","Return Variables:\n","queries - mapping from queryid to querytext\n","'''\n","\n","def loadQueries(queries_file):\n","  #enter your code here\n","  queries={}\n","  for line in open(queries_file,encoding='utf8'):\n","        qid,qtext=line.strip().split('\\t')\n","        queries[qid]=qtext\n","\n","  return queries\n","\n","\n","'''\n","This function is used to load feedback passages corresponding to the queries into a datastructure.\n","The file format is given below:\n","\"query_id passage_id1 passage_id2 .....   passage_id10\"\n","The entries are space separated.\n","\n","Return Variables:\n","num_queries - number of queries in the file\n","feedback_pass - mapping from queryid to list of feedback passages\n","'''\n","\n","\n","def loadFeedbackPass(query_pass):\n","     #enter your code here\n","     feedback_pass={}\n","     for line in open(\"query_pass\",encoding='utf8'):\n","          x=line.strip().split(' ')\n","          feedback_pass[x[0]]=x[1:]\n","\n","\n","     return feedback_pass\n","\n","\n","\n","queries = loadQueries(queries_file)\n","feedback_pass = loadFeedbackPass(query_pass)\n","\n","\n","print ('Total Num of queries in the query file  : {0}'.format(len(queries)))\n","print ('Total Num of queries in the feedback file  : {0}'.format(len(feedback_pass)))\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Num of queries in the query file  : 5\n","Total Num of queries in the feedback file  : 5\n"]}]},{"cell_type":"markdown","metadata":{"id":"lE5LNkC_Nz1j"},"source":["\n","In the cell below, an inverted index with count has been created in memory. Please run the cell and use the variables for implementing the relevance feedback models."]},{"cell_type":"code","metadata":{"id":"jGIELwv9N7WI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668223938021,"user_tz":300,"elapsed":21454,"user":{"displayName":"Harsh Shah","userId":"05727327381693060940"}},"outputId":"cddf452c-4d1d-49ab-91ef-3aa1680dac08"},"source":["'''\n","Store the feedback docids\n","'''\n","\n","def storeFeedbackPass(query_pass):\n","    feedback_pass_ids = {}\n","    for line in open(query_pass):\n","      row = line.strip().split(' ')\n","      for p in row[1:]:\n","        if p not in feedback_pass_ids:\n","          feedback_pass_ids[p]=0\n","        feedback_pass_ids[p]+=1\n","    return feedback_pass_ids\n","\n","feedback_pass_ids = storeFeedbackPass(query_pass)\n","\n","\n","'''\n","An inverted index with count information.\n","'''\n","class indexCount:\n","   pcount = 0\n","   ctf = {}\n","   sumdl = 0\n","   avgdl = 0\n","   doclen = {}\n","   index = {}\n","   probctf = {}\n","   feedback_pass_contents = {}\n","\n","   def __init__(self, col):\n","     self.col = col\n","\n","\n","   def create_index(self):\n","     for line in open(self.col):\n","       pid,ptext = line.strip().split('\\t')\n","       self.pcount+=1\n","\n","       if pid not in self.doclen:\n","           self.doclen[pid]=0\n","       pfreq = {}\n","       for term in ptext.split(' '):\n","           self.doclen[pid]+=1\n","\n","           if term not in pfreq:\n","              pfreq[term]=0\n","           pfreq[term]+=1\n","\n","\n","       for k,v in pfreq.items():\n","        if k not in self.index:\n","          self.index[k]={}\n","\n","        self.index[k][pid]=v\n","\n","       if pid in feedback_pass_ids:\n","          self.feedback_pass_contents[pid]=ptext\n","\n","\n","buildIndex = indexCount(col)\n","buildIndex.create_index()\n","\n","\n","'''\n","inverted index with count: nested dict with term and passage_id as key\"\n","Example - {'the': {'2020338_0:11', '3174498_1:4'}}\n","'''\n","index = buildIndex.index\n","\n","#total number of passages in the collection\n","num_passages = buildIndex.pcount\n","\n","#dict with passageId as key and number of terms in the passage as value\n","doclen = buildIndex.doclen\n","\n","#dict with passage id as key and passage text as value for feedback passages\n","feedback_pass_contents = buildIndex.feedback_pass_contents\n","\n","print('Total number of passages in the collection :{0}'.format(num_passages))\n","print('Total number of feedback passages :{0}'.format(len(feedback_pass_contents)))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of passages in the collection :403492\n","Total number of feedback passages :50\n"]}]},{"cell_type":"markdown","metadata":{"id":"HfbdH1gB-v_y"},"source":["# 2 : Query Language Model (30 points)\n","\n","In the cell below, calculate Maximum Likelihood Estimates for the Query Language Model, as follows:\n","\n","$P_{MLE}(t|q)$ = $\\frac{count(t,q)}{|q|}$\n","\n","$count(t,q)$ - Number of times term $t$ appears in query $q$\n","\n","$|q|$ - Number of tokens in query $q$\n","\n","Calculate the estimates for all queries.\n"]},{"cell_type":"code","metadata":{"id":"sFBeVDCqCOW7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668223938021,"user_tz":300,"elapsed":34,"user":{"displayName":"Harsh Shah","userId":"05727327381693060940"}},"outputId":"f08f612a-2642-4292-d744-e6f46cc9cded"},"source":["'''\n","In this function implement mle estimates for all queries.\n","Return Variables:\n","  mle_queries - mapping from queryid to mle estimates. The mle estimates for each query is a dict from each query word to its MLE probability.\n","'''\n","\n","def calcMleQueries(queries):\n","  #enter your code here\n","  mle_queries={}\n","  for q in queries:\n","        num_tokens =len(queries.get(q).split())\n","        query_vocab = []\n","        for word in queries.get(q).split():\n","            if word not in query_vocab:\n","                query_vocab.append(word)\n","\n","        query_wc = {}\n","        for word in query_vocab:\n","            query_wc[word] = queries.get(q).split().count(word)\n","\n","        mle={}\n","        for word in query_vocab:\n","            p=query_wc[word]/num_tokens\n","            mle[word]=p\n","        mle_queries[q]=mle\n","\n","  return mle_queries\n","\n","mle_queries = calcMleQueries(queries)\n","\n","# Hint: the MLE estimates are in the interval [0.10,0.20]\n","print('MLE estimates for qid 3396066 :{0}'.format(mle_queries['3396066']))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MLE estimates for qid 3396066 :{'why': 0.16666666666666666, 'do': 0.16666666666666666, 'airplane': 0.16666666666666666, 'fly': 0.16666666666666666, 'so': 0.16666666666666666, 'high': 0.16666666666666666}\n"]}]},{"cell_type":"markdown","metadata":{"id":"lYxT6jBrG7JW"},"source":["# 3 : Relevance Model 1 (RM1) (50 points)\n","\n","In the cell below, implement the RM1 feedback model, as follows.\n","\n","$$P_{RM1}(t|\\theta_{F}) \\propto \\sum_{p \\in F} (p(t|\\theta_{p}) \\prod_{w \\in q} p(w|\\theta_{p}))$$\n","\n","$p(t|\\theta_{p}) = \\frac{count(t,p) + \\delta}{|p| + \\delta|V|}$ ($p(w|\\theta_{p})$ is computed similarly)\n","\n","$\\delta = 0.1$\n","\n","$|V|$: vocabulary size (number of unique words in the vocabulary)\n","\n","$count(t,p)$ - Number of times term $t$ occurs in passage $p$\n","\n","$|p|$ - Number of tokens in passage $p$\n","\n","$F$: Feedback passages\n","\n","For every query, this has to be computed for all unique terms present in feedback passages.\n","\n","**Note:** Once you compute the weights for each term, you should normalize them by dividing by their sum. In other words, the RM1 probabilities for each query should sum to 1.\n"]},{"cell_type":"code","source":["query_vocab_dict={}\n","for q in queries:\n","        num_tokens =len(queries.get(q).split())\n","        query_vocab = []\n","        for word in queries.get(q).split():\n","            if word not in query_vocab:\n","                query_vocab.append(word)\n","\n","        query_wc = {}\n","        for word in query_vocab:\n","            query_wc[word] = queries.get(q).split().count(word)\n","        query_vocab_dict[q]=query_wc\n"],"metadata":{"id":"iKnC05AP4oKM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_qid={}\n","for qid in feedback_pass:\n","    l=feedback_pass[qid]\n","    feedback_vocab=[]\n","    for i in l:\n","        for word in feedback_pass_contents[i].split():\n","            if word not in feedback_vocab:\n","                feedback_vocab.append(word)\n","\n","    vocab_qid[qid]=feedback_vocab"],"metadata":{"id":"s0WzYgDD4ocn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def normalize(prm1):\n","    total=0\n","    for i in prm1:\n","        total=total+prm1[i]\n","    for i in prm1:\n","        prm1[i]=prm1[i]/total\n","\n","    return prm1\n"],"metadata":{"id":"eC-0CQrz4s10"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"seltwXRX98hm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668223938259,"user_tz":300,"elapsed":245,"user":{"displayName":"Harsh Shah","userId":"05727327381693060940"}},"outputId":"bcc62e79-4a0d-4ed9-ee3a-201287c96235"},"source":["'''\n","In this function implement RM1 and return words and their probabilities.\n","Return Variables:\n","rm1 - mapping from queryid to RM1 probabilities.\n","The RM1 probabilities for each query is a dict from the words that appear in the feedback passages to their RM1 probability.\n","'''\n","import collections\n","\n","def calcRM1(index,queries,doclen,feedback_pass,feedback_pass_contents):\n","    #enter your code here\n","\n","    rm1={}\n","    for qid in feedback_pass:\n","        prm1={}\n","        #first setting it to zero\n","        for w in vocab_qid[qid]:\n","            prm1[w]=0\n","\n","        for i in feedback_pass[qid]:\n","            qidx=1\n","            for word in query_vocab_dict[qid]:\n","                qwcount=query_vocab_dict[qid][word]\n","                #print(len(feedback_pass_contents[fp]),len(vocab_qid[qid]))\n","                qidx=qidx*(qwcount+0.1)/(len(feedback_pass_contents[i])+int(0.1*len(index)))\n","\n","\n","            for word in feedback_pass_contents[i].split():\n","                pwcount=feedback_pass_contents[i].count(word)\n","                x=(pwcount+0.1)/(len(feedback_pass_contents[i])+int(0.1*len(index)))\n","                #print(word,x)\n","                r=x*(qidx)\n","                prm1[word]=r\n","\n","        pnrm=normalize(prm1)\n","        rm1[qid]=pnrm\n","\n","    return rm1\n","\n","rm1 = calcRM1(index,queries,doclen,feedback_pass,feedback_pass_contents)\n","\n","'''\n","Print out top 20 terms and corresponding probabilities\n","this assumes that the rm1 variable returned is a dict with queryid as key and dict consisting of term and probability values as the value.\n","You can alter this based on your implementation.\n","'''\n","\n","rm1_scores = {}\n","rm1_final = {}\n","for k,v in rm1.items():\n","    if k not in rm1_final:\n","      rm1_final[k]=[]\n","    if k not in rm1_scores:\n","      rm1_scores[k]={}\n","    sorted_p = sorted(v.items(), key=lambda x: x[1], reverse=True)\n","    sorted_dict = collections.OrderedDict(sorted_p)\n","    for t,s in sorted_dict.items():\n","        rm1_final[k].append(t+\":\"+str(s))\n","        rm1_scores[k][t]=s\n","\n","''' Hint: The probability value or the top (1st) term is in the range [0.081,0.083]\n","          The probability value for the 20th term is in the range [0.0076,0.0078]'''\n","print('Top 20 Feedback terms and their RM1 probabilities for qid 3396066 :{0}'.format(rm1_final['3396066'][:20]))\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Top 20 Feedback terms and their RM1 probabilities for qid 3396066 :['i:0.05189559068351684', 't:0.045073874202802476', 'a:0.03832965362382953', 'u:0.030991937693658916', 's:0.026645732805317773', 'n:0.02146910217639719', 'an:0.01866466148141698', 'the:0.012201992135104929', 'ear:0.01160929116198101', 'm:0.010603420315491136', 'd:0.010603420315491136', 'helicopter:0.006954797369551261', 'to:0.0061614019692114', 'or:0.005836715446078849', 'cause:0.005836715446078849', 'pressure:0.005836715446078849', 'on:0.005732587492126997', 'balls:0.0050637836726273', 'in:0.004953283936032693', 'cloud:0.00491255895608429']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"1AisrYBz4m8p"},"execution_count":null,"outputs":[]}]}