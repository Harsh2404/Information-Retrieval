{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1pMf21xnln0sdV3aVOnSSaLMsCv_WVxSA","timestamp":1670606255952},{"file_id":"1I0v2iZPwZnplJc7iY0nzplek7lzhxmsr","timestamp":1657733493772},{"file_id":"1KBU6OpQcoZKP-1z7Izl5kRKnVKxI1Azw","timestamp":1648606122201},{"file_id":"1AJ9jnZsuPDE23l4sTo5-bMQfb9EYGziD","timestamp":1617061433749}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0KKC3O3QiIi4"},"source":["## ENGG*6600: Special Topics in Information Retrieval - Fall 2022\n","##Assignment 6: Clustering (Total : 100 points)\n","\n","**Description**\n","\n","This is a coding assignment where you will implement the k-means clustering algorithm to cluster passages. Basic proficiency in Python is recommended.  \n","\n","**Instructions**\n","\n","* To start working on the assignment, you would first need to save the notebook to your local Google Drive. For this purpose, you can click on *Copy to Drive* button. You can alternatively click the *Share* button located at the top right corner and click on *Copy Link* under *Get Link* to get a link and copy this notebook to your Google Drive.  \n","\n","*   For questions with descriptive answers, please replace the text in the cell which states \"Enter your answer here!\" with your answer. If you are using mathematical notation in your answers, please define the variables.\n","*   You should implement all the functions yourself and should not use a library or tool for the computation.\n","*   For coding questions, you can add code where it says \"enter code here\" and execute the cell to print the output.\n","* To create the final pdf submission file, execute *Runtime->RunAll* from the menu to re-execute all the cells and then generate a PDF using *File->Print->Save as PDF*. Make sure that the generated PDF contains all the codes and printed outputs before submission.\n","To create the final python submission file, click on File->Download .py.\n","\n","\n","**Submission Details**\n","\n","* Due data: November. 28, 2022 at 11:59 PM (EDT).\n","* The final PDF and python file must be uploaded on CourseLink.\n","* After copying this notebook to your Google Drive, please paste a link to it below. Use the same process given above to generate a link. ***You will not recieve any credit if you don't paste the link!*** Make sure we can access the file.\n","***LINK: *https://colab.research.google.com/drive/1pU2XaxvD1UhkTdBlq1ecevmwYQ_wvVTp?usp=sharing***\n","\n","**Academic Honesty**\n","\n","Please follow the guidelines under the *Collaboration and Help* section in the first lecture.      "]},{"cell_type":"markdown","metadata":{"id":"JuVqvXU6ijXi"},"source":["# Download input files"]},{"cell_type":"markdown","metadata":{"id":"SMU5d1a-jCG-"},"source":["Please execute the cell below to download the input files."]},{"cell_type":"code","metadata":{"id":"YM1igiBMcIB8"},"source":["\n","import os\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","\n","import os\n","import zipfile\n","import numpy as np\n","\n","download = drive.CreateFile({'id': '1NR5jMPJAJHD3flGEbckMr8WerfPtLtZ2'})\n","download.GetContentFile('HW06.zip')\n","\n","with zipfile.ZipFile('HW06.zip', 'r') as zip_file:\n","    zip_file.extractall('./')\n","os.remove('HW06.zip')\n","# We will use hw05 as our working directory\n","os.chdir('HW06')\n","\n","#Setting the input file\n","passage = \"passages.tok.clean_kstem\"\n","init_centroid_file = \"centroid.txt\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L84x5CFj9Z-L"},"source":["# 1 : Initial Data Setup (25 points)\n","\n","We use collection from the ANTIQUE  [https://arxiv.org/pdf/1905.08957.pdf] dataset for this assignment. As described in the previous assignments, this is a passage retrieval dataset.\n","\n","The description of the input files provided for this assignment is given below.\n","\n","**Collection file**\n","\n","Each row of the file consists of the following information:\n","\n","*passage_id  passage_text*\n","\n","The id and text information is tab separated. The passage text has been pre-processed to remove punctutation, tokenised and stemmed using the Krovetz stemmer. The terms in the passage text can be accessed by splitting the text based on space.\n","\n","**Centroid vector values**\n","\n","Each row is a tab separated entry where the first column is cluster id and the second column is the vector which is used to initialize the cluster centroid in the k-means Algorithm.\n","\n","In the cell below, collection information as vocababulary size, document frequency and passage count and initial centroid vector values have been given. This can be used in subsequent cells for computation.\n","\n"]},{"cell_type":"code","metadata":{"id":"c7pEmMOeaoMa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670607641688,"user_tz":300,"elapsed":20,"user":{"displayName":"Harsh Shah","userId":"05727327381693060940"}},"outputId":"ee5c55db-5adc-48a8-b227-e190bd32fdb0"},"source":["'''\n","In this function, load the initial centroid values for k clusters.\n","Return Variables:\n","init_centroid_vec - array where each element corresponds to the centroid vector.\n","'''\n","\n","# load initial centroid values\n","def load_centroid_init(init_centroid_file):\n","  init_centroid_vec = []\n","  for line in open(init_centroid_file):\n","   row = line.strip().split('\\t')\n","   init_centroid_vec.append(np.fromstring(row[1][1:-1],sep=',').astype(float))\n","  return init_centroid_vec\n","\n","\n","'''\n","In this function, iterate through the input passage and load the data\n","Return Variables:\n","vocab - dict mapping word to an integer [0,len(vocab)]\n","df - dict mapping word to document frquency\n","num_passages - total number of passages in the input collection\n","docs - dict mapping each passage id to unique integer between [0,len(num_passages)]\n","'''\n","# load vocabulary\n","def load_vocab(passage):\n","  df = {}\n","  vocab = {}\n","  count = 0\n","  doc_count = 0\n","  num_passages = 0\n","  docs = {}\n","  for line in open(passage):\n","   row = line.strip().split('\\t')\n","   docs[row[0]] = doc_count\n","   doc_count+=1\n","   terms = row[1].split(' ')\n","   num_passages+=1\n","   for word in set(terms):\n","    if word not in df:\n","      df[word]=0\n","    df[word]+=1\n","   for word in terms:\n","    if word not in vocab:\n","      vocab[word]=count\n","      count+=1\n","\n","  return vocab,df,num_passages,docs\n","\n","init_centroid_vec = load_centroid_init(init_centroid_file)\n","vocab, df, num_passages, docs = load_vocab(passage)\n","\n","print('Vocabulary Size : {0}'.format(len(vocab)))\n","print('Total Number of Passages: {0}'.format(num_passages))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary Size : 3630\n","Total Number of Passages: 500\n"]}]},{"cell_type":"markdown","metadata":{"id":"dq54VT8zcMjr"},"source":["**Passage Representation**\n","\n","In order to cluster passages, each passage has to be converted into a vector representation. For this assignment, we choose a $tf{\\text -}idf$ representation. Every passage is represented by a vector with dimensionality equal to vocab_size. Each dimension in the vector corresponds to a word. The value of each dimension of the vector is the $tf{\\text -}idf$ value of the word in that passage. These vectors can be stacked to create a matrix where each row of the matrix corresponds to a passage.\n","\n","Let the vocab_size be $n$ and num_passages be $m$.\n","\n","In the cell below, implement the following:\n","\n","1) Create an input data matrix $P = m \\times n$  where $P_{i,j}=tf{\\text -}idf(i,j)$. The definition of the $tf{\\text -}idf(i,j)$ formulation is given below.\n","\n","$$ tf{\\text -}idf(i,j) = ln(1+count(i,j)) ln(1 + \\frac{|C|}{df(j)}) $$\n","\n","\n","$tf{\\text -}idf(i,j)$: the  $tf{\\text -}idf$ value of the word corresponding to integer $j$ and passage corresponding to integer $i$ as defined in vocab and docs data structures, respectively.\n","\n","$count(i,j)$ = number of times word corresponding to integer $j$ occurs in passage corresponding to integer $i$.\n","\n","$df(j)$ - The document frequency of word corresponding to integer $j$ (i.e., the number of documents that contain the $j^{th}$ word.\n","\n","$|C|$ - Total number of passages in the collection.\n"]},{"cell_type":"code","metadata":{"id":"-fIEB5l56-o-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670607655302,"user_tz":300,"elapsed":13626,"user":{"displayName":"Harsh Shah","userId":"05727327381693060940"}},"outputId":"2115162d-fdc8-4645-cce4-7d3f7b01562b"},"source":["'''\n","In this function, create input matrix\n","Return Variables:\n","pass_matrix - matrix of shape m by n where each row corresponds to a passage and each column to a word\n","'''\n","passages={}\n","for line in open(passage,encoding='utf8'):\n","    pid,psg=line.strip().split('\\t')\n","    passages[pid]=[psg]\n","\n","vocab_keys=list(vocab.keys())\n","\n","def create_input_matrix(passage,df,num_passages,vocab):\n","    #enter code here\n","    pass_matrix=np.zeros((num_passages,len(vocab)))\n","    for i,p in enumerate(passages):\n","        for j,word in enumerate(vocab_keys):\n","            count=str(passages[p]).lower().split().count(word)\n","            tf=np.log(1+count)\n","            x=num_passages/df[word]\n","            idf=np.log(1+x)\n","            tfidf=tf*idf\n","            pass_matrix[i][j]=tfidf\n","\n","    return pass_matrix\n","\n","pass_matrix =  create_input_matrix(passage,df,num_passages,vocab)\n","\n","print('Shape of the input matrix : {0}'.format(np.shape(pass_matrix)))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the input matrix : (500, 3630)\n"]}]},{"cell_type":"markdown","metadata":{"id":"1V1g6gnbGrtR"},"source":["# 2 :  k-means Algorithm (45 points)\n","\n","In this section you must implement the k-means clustering algorithm. The K-means function is called with $k=3$ ($k$ is the number of clusters) and the initial centroids have been set for you, the distance metric to be used is the squared Euclidean distance. Execute the algorithm for 30 iterations.\n"]},{"cell_type":"code","source":["\n","# centroid is a matrix instantiated with initial centroid values\n","'''\n","In this function, centroid is instantiated with initial centroid values\n","Here we assume for k=3, the cluster ids are {0,1,2}\n","Return Variables:\n","centroid - matrix where rows correspond to clusters and columns correspond to words.\n","'''\n","def  init_centers(vocab, k, init_centroid_vec):\n","  vocab_size = len(vocab)\n","  centroid = np.zeros((k, vocab_size), dtype='float')\n","  for i in range(len(init_centroid_vec)):\n","     centroid[i] = init_centroid_vec[i]\n","  return centroid\n","\n","centroid = init_centers(vocab, 3, init_centroid_vec)"],"metadata":{"id":"yuKMeYSo5prR"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6Sssau6MO-o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670607655867,"user_tz":300,"elapsed":603,"user":{"displayName":"Harsh Shah","userId":"05727327381693060940"}},"outputId":"4aa8078f-149b-480f-83b4-f50481b8be57"},"source":["'''\n","In this function, implement kmeans algorithm\n","Return Variables:\n","final_cluster_assignment - array with cluster id values indexed by the passageid (integer mappings in docs)\n","num_passage_cluster_final - dict with cluster-id and key and number of elements in the cluster as value\n","'''\n","def kmeans(num_passages, pass_matrix, centroid, k):\n","  final_cluster_assignment = [0] * num_passages\n","  num_passage_cluster_final = {}\n","\n","  for i in range(30):\n","    for p in range(num_passages):\n","      init = np.inf\n","      for c in range(k):\n","        dist = np.linalg.norm(pass_matrix[p]-centroid[c])\n","\n","        if(init > dist):\n","          init = dist;\n","          final_cluster_assignment[p] = c\n","\n","    clust = [0] * k\n","    avg_centroid = [[0]* len(centroid[0])] * k\n","    for p in range(num_passages):\n","      cv = final_cluster_assignment[p]\n","      clust[cv] += 1\n","      avg_centroid[cv] = np.add(avg_centroid[cv] ,pass_matrix[p])\n","\n","    for n in range(k):\n","      centroid[n] = avg_centroid[n]/clust[n]\n","\n","  for c in range(k):\n","    num_passage_cluster_final[c] = final_cluster_assignment.count(c)\n","\n","  return final_cluster_assignment,num_passage_cluster_final\n","\n","\n","\n","final_cluster_assignment, num_passage_cluster_final = kmeans(num_passages, pass_matrix, centroid, 3)\n","\n","print('Number of initial centroids : {0}'.format(len(centroid)) )\n","\n","# print number of elements in each cluster\n","'''\n"," Hint: The values lies within the interval [360,370] for the largest cluster,\n"," [120,130] for the second largest cluster and [0,10] for the smallest cluster.\n","'''\n","for cid,cnum in num_passage_cluster_final.items():\n","   print(cid, cnum)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of initial centroids : 3\n","0 371\n","1 120\n","2 9\n"]}]},{"cell_type":"markdown","metadata":{"id":"-pyCSMB1MOaA"},"source":["# 3 :  Evaluation (30 points)\n","\n","In this section, you must implement two evaluation metrics:\n","\n","1) IntraCluster Similarity Metric - Average Diameter\n","Distance of each cluster $S$\n","\n","$$Sim(S) = \\frac{1}{|S| (|S|-1)} \\sum_{x,y \\in S,x \\neq y} dist(x,y)$$\n","\n","$|S|$ - number of passages assigned to cluster $S$\n","\n","$dist(x,y)$ - the squared euclidean distance between passages $x$ and $y$.\n","\n","\n","2) Intercluster Similarity Metric -\n","Average Linkage Distance between a pair of clusters $S,T$\n","\n","$$Sim(S,T) = \\frac{1}{|S| |T|} \\sum_{x \\in S,y \\in T} dist(x,y)$$\n","\n","$|S|$ - number of passages assigned to cluster $S$\n","\n","$|T|$ - number of passages assigned to cluster $T$\n","\n","$dist(x,y)$ - the squared euclidean distance between passages $x$ and $y$.\n","\n","\n","You have to calculate and print out the IntraCluster Similarity Metric for every cluster and Intercluster Similarity Metric for every cluster pair. This is illustrated below with examples.\n","\n","For IntraCluster metric, Average Diameter Distance for cluster (a, b, c),\n","the value can be calculated as follows :$\\frac{dist(a, b)+dist(a, c)+dist(b, a)+dist(b, c)+ dist(c, a)+ dist(c, b)}{3*2} $\n","\n","For InterCluster metric, Average Linkage Distance for clusters (a, b, c) and (d, e) , the value can be calculated as follows:  $\\frac{dist(a, d)+dist(a, e)+ dist(b, d)+ dist(b, e)+ dist (c, d)+ dist(c, e)}{3*2}$\n","\n"]},{"cell_type":"code","metadata":{"id":"CQ8S-4ybMXgu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670607657788,"user_tz":300,"elapsed":1930,"user":{"displayName":"Harsh Shah","userId":"05727327381693060940"}},"outputId":"3e624516-2f24-45e4-a4cd-f1657a504fd5"},"source":["def average_diameter_dist(num_passage_cluster_final,final_cluster_assignment,pass_matrix):\n","    sim_score = {}\n","    k = 3\n","\n","    for c in range(k):\n","      clust_list = []\n","      for idx, value in enumerate(final_cluster_assignment):\n","        if value == c:\n","          clust_list.append(idx)\n","\n","      dist = 0.0\n","      for i in range(len(clust_list)):\n","        for j in range(i+1,len(clust_list)):\n","          dist += np.sum(np.square(pass_matrix[clust_list[i]]-pass_matrix[clust_list[j]]))\n","\n","      num_p_clust = num_passage_cluster_final[c]\n","      sim_s = 1/(num_p_clust*(num_p_clust-1))\n","\n","      sim_score[c] = (sim_s * dist*2)\n","\n","    return sim_score\n","\n","'''\n","In this function, implement intercluster similarity metric Average Linkage Distance\n","Return Variables:\n","sim_score - dict with metric score corresponding to each pair of clusters\n","'''\n","def average_linkage_dist(num_passage_cluster_final,final_cluster_assignment,pass_matrix):\n","    sim_score = {}\n","    k = 3\n","    p = 0\n","    for c1 in range(k-1):\n","      clust_list1 = []\n","\n","      num_p_clust1 = num_passage_cluster_final[c1]\n","      for idx, value in enumerate(final_cluster_assignment):\n","          if value == c1:\n","            clust_list1.append(idx)\n","\n","      for c2 in range(c1+1,k):\n","        clust_list2 = []\n","        for idx, value in enumerate(final_cluster_assignment):\n","          if value == c2:\n","            clust_list2.append(idx)\n","\n","        eucl_Dist = 0.0\n","        for i in range(len(clust_list1)):\n","          for j in range(len(clust_list2)):\n","            eucl_Dist += np.sum(np.square(pass_matrix[clust_list1[i]]-pass_matrix[clust_list2[j]]))\n","\n","        num_p_clust2 = num_passage_cluster_final[c2]\n","        sim_s_t = 1/(num_p_clust1*num_p_clust2)\n","\n","        sim_score[p] = (sim_s_t * eucl_Dist)\n","        p = p + 1\n","\n","    return sim_score\n","\n","intra_score  = average_diameter_dist(num_passage_cluster_final,final_cluster_assignment,pass_matrix)\n","inter_score =  average_linkage_dist(num_passage_cluster_final,final_cluster_assignment,pass_matrix)\n","\n","# print intracluster scores for very cluster\n","'''\n","Hint: The value lies within the intervals [310,320] for the largest cluster,\n","[1135,1145] for the second largest cluster and [3860,3870] for the smallest cluster.\n","'''\n","for cid,score in intra_score.items():\n","   print(cid, score)\n","\n","# print intercluster scores for every pair of cluster\n","'''\n","Hint: The value lies within the intervals [740,750] between largest and second largest clusters.\n","[2260,2270] between largest and smallest clusters and\n","[2590,2600] between second largest and smallest cluster\n","'''\n","for cid_pair,score in inter_score.items():\n","   print(cid_pair, score)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 297.02340250235443\n","1 1129.4317675677546\n","2 3829.755796558129\n","0 728.5627971555085\n","1 2238.5859474342788\n","2 2572.1757538320253\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"T9TWlivj6C6L"},"execution_count":null,"outputs":[]}]}
